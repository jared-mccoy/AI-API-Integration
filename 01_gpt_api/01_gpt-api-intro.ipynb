{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd15cb0",
   "metadata": {},
   "source": [
    "# GPT API Introduction\n",
    "\n",
    "In this notebook, we'll explore the basics of using the OpenAI GPT API, starting from the very beginning with setting up the environment and connecting to the API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6025769",
   "metadata": {},
   "source": [
    "## 1. Setting Up Your OpenAI Account\n",
    "\n",
    "Before using the OpenAI API, you need to create an account and obtain an API key. Follow these steps:\n",
    "1. Visit the [OpenAI website](https://openai.com/) and sign up for an account.\n",
    "2. Verify your email address to activate your account.\n",
    "3. Navigate to the API section of your account dashboard.\n",
    "4. Click on \"Create API Key\" to generate a new token.\n",
    "5. Copy the generated token and store it securely, as it will be used to authenticate your API requests.\n",
    "\n",
    "> ### Understanding Usage Charges\n",
    "> \n",
    "> The pricing for the GPT-3.5-turbo model is **$0.002 per 1,000 tokens**. \n",
    "> - **What is a Token?** A token can be as short as one character or as long as one word. On average, 1,000 tokens correspond to about 750 words.\n",
    "> - **Cost Examples**:\n",
    ">   - **100 tokens**: ~$0.0002 (about 75 words)\n",
    ">   - **500 tokens**: ~$0.001 (about 375 words)\n",
    ">   - **1,000 tokens**: ~$0.002 (about 750 words)\n",
    ">   - **5,000 tokens**: ~$0.01 (about 3,750 words)\n",
    "> \n",
    "> This makes it affordable to experiment with the API without incurring significant expenses. Always check the [OpenAI pricing page](https://openai.com/pricing) for the most up-to-date information on usage charges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c877d",
   "metadata": {},
   "source": [
    "## 2. Setting up the Environment\n",
    "\n",
    "First, we need to ensure that we have the necessary packages installed. The main package we'll be using is `openai`. Let's create a function to check if it's installed and install it if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e632d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "def check_openai_installed():\n",
    "    if importlib.util.find_spec(\"openai\") is None:\n",
    "        print(\"OpenAI package not found. Installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"openai\"])\n",
    "        print(\"OpenAI package installed successfully.\")\n",
    "    else:\n",
    "        print(\"OpenAI package is already installed.\")\n",
    "\n",
    "check_openai_installed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a811c9c1",
   "metadata": {},
   "source": [
    "## 3. Importing the OpenAI Library and Setting up the API Key\n",
    "\n",
    "Now that we've ensured the `openai` package is installed, let's import it and set up the API key.\n",
    "\n",
    "To use the OpenAI API, we need an API key. It's important to keep this key secure. If you cloned the repository locally, you can simply add your API key to a `.env` file in the root directory of the project. This way, you won't need to re-enter your API key each time you run the notebook.\n",
    "\n",
    "> **Note on Security**: When entering your API key in Jupyter notebooks or Google Colab, be cautious. Avoid sharing your notebooks publicly or exposing your API key in any way. Always ensure that your API key is kept private to prevent unauthorized access to your OpenAI account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a96e1a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def validate_api_key(api_key):\n",
    "    try:\n",
    "        client = OpenAI(api_key=api_key)\n",
    "        # Make a simple API call to test the key\n",
    "        client.models.list()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error validating API key: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def get_api_key():\n",
    "    while True:\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not api_key:\n",
    "            print(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "            api_key = getpass(\"Please enter your OpenAI API key: \")\n",
    "        \n",
    "        if validate_api_key(api_key):\n",
    "            os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "            return api_key\n",
    "        else:\n",
    "            print(\"Invalid API key. Please try again.\")\n",
    "            os.environ.pop(\"OPENAI_API_KEY\", None)  # Remove the invalid key from env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74524938",
   "metadata": {},
   "source": [
    "## 4. Setting up the OpenAI Client\n",
    "\n",
    "In this step, we will set up the OpenAI client using the validated API key. This client will be used to make requests to the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176b24d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "_client = None\n",
    "\n",
    "def setup_openai_client():\n",
    "    global _client\n",
    "    api_key = get_api_key()\n",
    "    _client = OpenAI(api_key=api_key)\n",
    "    print(f\"API Key set: {'Yes' if _client.api_key else 'No'}\")\n",
    "    print(f\"API Key (first 5 chars): {_client.api_key[:5] if _client.api_key else 'None'}\")\n",
    "    return _client\n",
    "\n",
    "client = setup_openai_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343587ba",
   "metadata": {},
   "source": [
    "## 5. Testing the API Connection\n",
    "\n",
    "Here, we will test the API connection by making a simple request to ensure that the client is set up correctly and the API key is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008bdc45",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_api(client):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Hello, World!\"}\n",
    "            ],\n",
    "            max_tokens=10  # Increase max_tokens for a longer response\n",
    "        )\n",
    "        print(\"API test successful. Response:\", response.choices[0].message.content.strip())\n",
    "    except Exception as e:\n",
    "        print(\"API test failed. Error:\", str(e))\n",
    "\n",
    "# Test the API connection\n",
    "test_api(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72d1a9c",
   "metadata": {},
   "source": [
    "## 6. Generating Text with GPT\n",
    "\n",
    "In this step, we will define a function to generate text using the GPT model based on a user-provided prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f19bf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    global _client\n",
    "    if _client is None:\n",
    "        _client = setup_openai_client()\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = _client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test the text generation\n",
    "prompt = \"Write a short poem about artificial intelligence:\"\n",
    "generated_poem = get_completion(prompt)\n",
    "print(\"\\nGenerated Poem:\")\n",
    "print(generated_poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c9edb",
   "metadata": {},
   "source": [
    "## 7. Helper Function and Minification\n",
    "\n",
    "In this step, we will create a helper function that encapsulates all the setup code into a minified format for easier reuse in future sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minified_helper():\n",
    "    import inspect\n",
    "    functions = [check_openai_installed, validate_api_key, get_api_key, setup_openai_client, get_completion]\n",
    "    minified_code = \"import importlib,subprocess,sys,os,getpass\\n_client=None\\n\"\n",
    "    for func in functions:\n",
    "        code = inspect.getsource(func)\n",
    "        # Basic minification (remove comments and extra whitespace)\n",
    "        minified_code += \"\\n\".join(line.strip() for line in code.split(\"\\n\") if line.strip() and not line.strip().startswith(\"#\"))\n",
    "    return f\"exec('''{minified_code}''')\\nclient=setup_openai_client()\"\n",
    "\n",
    "minified_helper = create_minified_helper()\n",
    "print(\"Minified Helper Function:\")\n",
    "print(minified_helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d818c5a7",
   "metadata": {},
   "source": [
    "This minified helper function combines all the necessary setup code into a single, compact string that can be executed with `exec()`. \n",
    "\n",
    "> ### Note on Security\n",
    "> \n",
    "> **Entering Your API Key**: When entering your API key in Jupyter notebooks or Google Colab, be cautious. Avoid sharing your notebooks publicly or exposing your API key in any way. If you cloned the repository locally, you can add your API key to a `.env` file in the root directory to avoid re-entering it each time.\n",
    "> \n",
    "> **Using `exec()`**: Using `exec()` can be a security risk if the code being executed is not trusted. In this case, we're generating the code ourselves, so it's safe. However, always be cautious when using `exec()` with any code that could be influenced by external input.\n",
    "> \n",
    "> **Cross-Platform Support**: By minifying the code and using `exec()`, we avoid issues with complex file paths and imports that can vary across different platforms, making our setup more portable. In private development environments like GitHub Codespaces, the risks of using `exec()` are minimized, as the code runs in a controlled environment.\n",
    "> \n",
    "> **Inspecting Code**: There is no real risk of malicious code, but you can always inspect this code (or have GPT inspect it beforehand).\n",
    "\n",
    "> **Disclaimer**: The author accepts no responsibility for any misuses of the authored code or any consequences that may arise from its use. Always ensure you understand the code you are executing and use it responsibly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c79fb3",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Now that we have our API connection set up and working, try experimenting with the following tasks to get a better understanding of how to manipulate the parameters of the GPT API:\n",
    "\n",
    "### 1. Change the Role and Content\n",
    "Modify the role of the assistant in the prompt. For example, change the role from \"user\" to \"system\" or \"assistant\" and see how the response changes.\n",
    "- **Hint**: You can adjust the `messages` parameter in the `get_completion` function to include different roles.\n",
    "- **Example**: \n",
    "  ```python\n",
    "  messages = [\n",
    "      {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "  ]\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3ce4c",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "# Change the Role and Content\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    max_tokens=50\n",
    ")\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d22566",
   "metadata": {},
   "source": [
    "### 2. Adjust the Temperature\n",
    "Experiment with the `temperature` parameter to see how it affects the creativity of the responses. A lower temperature (e.g., 0.2) will make the output more focused and deterministic, while a higher temperature (e.g., 0.8) will produce more varied and creative responses.\n",
    "- **Hint**: Modify the `temperature` argument in the `get_completion` function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb14ca",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "# Adjust the Temperature\n",
    "prompt = \"Write a creative story about a dragon.\"\n",
    "generated_text = get_completion(prompt, temperature=0.5)  # Change the temperature value\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829f8e8",
   "metadata": {},
   "source": [
    "### 3. Change the Max Tokens\n",
    "Adjust the `max_tokens` parameter to control the length of the generated response. Try setting it to different values (e.g., 50, 100, 200) and observe how the length and detail of the output change.\n",
    "- **Hint**: You can modify the `max_tokens` argument in the `get_completion` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c800fce",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "# Change the Max Tokens\n",
    "prompt = \"Explain the theory of relativity in simple terms.\"\n",
    "generated_text = get_completion(prompt, max_tokens=100)  # Change the max_tokens value\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d460e",
   "metadata": {},
   "source": [
    "Feel free to explore and combine these parameters to see how they interact with each other and affect the output!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
